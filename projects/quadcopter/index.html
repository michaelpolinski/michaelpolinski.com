<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Search and Rescue Quadcopter | Michael Polinski</title><meta name=keywords content><meta name=description content="As a makerfaire project, I worked with a friend to build a quadcopter with some search-and-rescue features. The quadcopter&rsquo;s FPV video is processed by OpenCV to detect humans in the vicinity.
To build the quadcopter, we followed a guide for 3D printing and assembling a Tiny Whoop quadcopter. To maximize the flying time, we carefullly chose the lightest possible components and optimal batteries. The quadcopter contains a FPV camera that streams video to the receiver, where it is displayed on a low-latency monitor for the pilot and fed to a laptop for processing using computer vision."><meta name=author content><link rel=canonical href=https://www.michaelpolinski.com/projects/quadcopter/><link crossorigin=anonymous href=/assets/css/stylesheet.min.343e026cf64e2528ea6810a04b81cbdfccc9a7612f4a3df38438ebf0853ba5da.css integrity="sha256-ND4CbPZOJSjqaBCgS4HL38zJp2EvSj3zhDjr8IU7pdo=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><meta name=generator content="Hugo 0.91.2"><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style><link href=https://www.michaelpolinski.com/favicon.ico rel=icon sizes=any><link href=https://www.michaelpolinski.com/favicon.svg rel=icon type=image/svg+xml><link href=https://www.michaelpolinski.com/apple-touch-icon.png rel=apple-touch-icon><link href=https://www.michaelpolinski.com/site.webmanifest rel=manifest><meta name=theme-color content="#005eff"><meta name=msapplication-TileColor content="#005eff"><meta property="og:title" content="Search and Rescue Quadcopter"><meta property="og:description" content="As a makerfaire project, I worked with a friend to build a quadcopter with some search-and-rescue features. The quadcopter&rsquo;s FPV video is processed by OpenCV to detect humans in the vicinity.
To build the quadcopter, we followed a guide for 3D printing and assembling a Tiny Whoop quadcopter. To maximize the flying time, we carefullly chose the lightest possible components and optimal batteries. The quadcopter contains a FPV camera that streams video to the receiver, where it is displayed on a low-latency monitor for the pilot and fed to a laptop for processing using computer vision."><meta property="og:type" content="article"><meta property="og:url" content="https://www.michaelpolinski.com/projects/quadcopter/"><meta property="article:section" content="projects"><meta property="article:published_time" content="2018-05-20T00:00:00+00:00"><meta property="article:modified_time" content="2018-05-20T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Search and Rescue Quadcopter"><meta name=twitter:description content="As a makerfaire project, I worked with a friend to build a quadcopter with some search-and-rescue features. The quadcopter&rsquo;s FPV video is processed by OpenCV to detect humans in the vicinity.
To build the quadcopter, we followed a guide for 3D printing and assembling a Tiny Whoop quadcopter. To maximize the flying time, we carefullly chose the lightest possible components and optimal batteries. The quadcopter contains a FPV camera that streams video to the receiver, where it is displayed on a low-latency monitor for the pilot and fed to a laptop for processing using computer vision."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Projects","item":"https://www.michaelpolinski.com/projects/"},{"@type":"ListItem","position":3,"name":"Search and Rescue Quadcopter","item":"https://www.michaelpolinski.com/projects/quadcopter/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Search and Rescue Quadcopter","name":"Search and Rescue Quadcopter","description":"As a makerfaire project, I worked with a friend to build a quadcopter with some search-and-rescue features. The quadcopter\u0026rsquo;s FPV video is processed by OpenCV to detect humans in the vicinity.\nTo build the quadcopter, we followed a guide for 3D printing and assembling a Tiny Whoop quadcopter. To maximize the flying time, we carefullly chose the lightest possible components and optimal batteries. The quadcopter contains a FPV camera that streams video to the receiver, where it is displayed on a low-latency monitor for the pilot and fed to a laptop for processing using computer vision.","keywords":[],"articleBody":"As a makerfaire project, I worked with a friend to build a quadcopter with some search-and-rescue features. The quadcopter’s FPV video is processed by OpenCV to detect humans in the vicinity.\nTo build the quadcopter, we followed a guide for 3D printing and assembling a Tiny Whoop quadcopter. To maximize the flying time, we carefullly chose the lightest possible components and optimal batteries. The quadcopter contains a FPV camera that streams video to the receiver, where it is displayed on a low-latency monitor for the pilot and fed to a laptop for processing using computer vision. After tuning the PID parameters to stabilize the quadcopter’s flight, we adapted a Python script that detects humans in the video using the computer vision library OpenCV.\nWe also presented the project at Northwestern University’s High School Project Showcase, where it received a first-place award in engineering projects.\nHere is the Python code we used followed by some photos of the components.\nfrom imutils.object_detection import non_max_suppression from imutils import paths import numpy as np import imutils import cv2 screen_size=(1920,1080) cap = cv2.VideoCapture(0) hog = cv2.HOGDescriptor() hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector()) frame = 0 cv2.namedWindow(\"Result\",cv2.WND_PROP_FULLSCREEN) cv2.setWindowProperty(\"Result\",cv2.WND_PROP_FULLSCREEN,cv2.WINDOW_FULLSCREEN) while cap.isOpened(): ret, image = cap.read() frame += 1 if (frame % 5 == 0): frame = 0 image = imutils.resize(image, width=min(300, image.shape[1])) orig = image.copy() # detect people in the image (rects, weights) = hog.detectMultiScale(image, winStride=(4, 4),padding=(8, 8), scale=1.05) # draw bounding boxes for (x, y, w, h) in rects: cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2) rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects]) pick = non_max_suppression(rects, probs=None, overlapThresh=0.65) for (xA, yA, xB, yB) in pick: cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2) # show the output images cv2.imshow(\"Result\", cv2.resize(image, screen_size)) key=cv2.waitKey(1) # ms delay if key==27: cap.release() cv2.destroyAllWindows() break cap.release() cv2.destroyAllWindows() ","wordCount":"308","inLanguage":"en","datePublished":"2018-05-20T00:00:00Z","dateModified":"2018-05-20T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.michaelpolinski.com/projects/quadcopter/"},"publisher":{"@type":"Organization","name":"Michael Polinski","logo":{"@type":"ImageObject","url":"https://www.michaelpolinski.com/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://www.michaelpolinski.com accesskey=h title="Michael Polinski (Alt + H)">Michael Polinski</a>
<span class=logo-switches></span></div><ul id=menu><li><a href=https://www.michaelpolinski.com/about/ title="About Me"><span>About Me</span></a></li><li><a href=https://www.michaelpolinski.com/contact/ title=Contact><span>Contact</span></a></li><li><a href=https://www.michaelpolinski.com/projects/ title=Projects><span>Projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Search and Rescue Quadcopter</h1><div class=post-meta><span title="2018-05-20 00:00:00 +0000 UTC">May 20, 2018</span></div></header><div class=post-content><p>As a makerfaire project, I worked with a friend to build a quadcopter with some search-and-rescue features. The quadcopter&rsquo;s FPV video is processed by OpenCV to detect humans in the vicinity.</p><p>To build the quadcopter, we followed a guide for 3D printing and assembling a Tiny Whoop quadcopter. To maximize the flying time, we carefullly chose the lightest possible components and optimal batteries. The quadcopter contains a FPV camera that streams video to the receiver, where it is displayed on a low-latency monitor for the pilot and fed to a laptop for processing using computer vision. After tuning the PID parameters to stabilize the quadcopter&rsquo;s flight, we adapted a Python script that detects humans in the video using the computer vision library OpenCV.</p><p>We also presented the project at Northwestern University&rsquo;s High School Project Showcase, where it received a first-place award in engineering projects.</p><p>Here is the Python code we used followed by some photos of the components.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> imutils.object_detection <span style=color:#f92672>import</span> non_max_suppression
<span style=color:#f92672>from</span> imutils <span style=color:#f92672>import</span> paths
<span style=color:#f92672>import</span> numpy <span style=color:#66d9ef>as</span> np
<span style=color:#f92672>import</span> imutils
<span style=color:#f92672>import</span> cv2

screen_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>1920</span>,<span style=color:#ae81ff>1080</span>) 
cap <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>VideoCapture(<span style=color:#ae81ff>0</span>)
hog <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>HOGDescriptor()
hog<span style=color:#f92672>.</span>setSVMDetector(cv2<span style=color:#f92672>.</span>HOGDescriptor_getDefaultPeopleDetector())
frame <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
cv2<span style=color:#f92672>.</span>namedWindow(<span style=color:#e6db74>&#34;Result&#34;</span>,cv2<span style=color:#f92672>.</span>WND_PROP_FULLSCREEN)
cv2<span style=color:#f92672>.</span>setWindowProperty(<span style=color:#e6db74>&#34;Result&#34;</span>,cv2<span style=color:#f92672>.</span>WND_PROP_FULLSCREEN,cv2<span style=color:#f92672>.</span>WINDOW_FULLSCREEN)
<span style=color:#66d9ef>while</span> cap<span style=color:#f92672>.</span>isOpened():
    ret, image <span style=color:#f92672>=</span> cap<span style=color:#f92672>.</span>read()
    frame <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
    <span style=color:#66d9ef>if</span> (frame <span style=color:#f92672>%</span> <span style=color:#ae81ff>5</span> <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>):
        frame <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
        image <span style=color:#f92672>=</span> imutils<span style=color:#f92672>.</span>resize(image, width<span style=color:#f92672>=</span>min(<span style=color:#ae81ff>300</span>, image<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>]))
        orig <span style=color:#f92672>=</span> image<span style=color:#f92672>.</span>copy()
        <span style=color:#75715e># detect people in the image</span>
        (rects, weights) <span style=color:#f92672>=</span> hog<span style=color:#f92672>.</span>detectMultiScale(image, winStride<span style=color:#f92672>=</span>(<span style=color:#ae81ff>4</span>, <span style=color:#ae81ff>4</span>),padding<span style=color:#f92672>=</span>(<span style=color:#ae81ff>8</span>, <span style=color:#ae81ff>8</span>), scale<span style=color:#f92672>=</span><span style=color:#ae81ff>1.05</span>)
        <span style=color:#75715e># draw bounding boxes</span>
        <span style=color:#66d9ef>for</span> (x, y, w, h) <span style=color:#f92672>in</span> rects:
            cv2<span style=color:#f92672>.</span>rectangle(orig, (x, y), (x <span style=color:#f92672>+</span> w, y <span style=color:#f92672>+</span> h), (<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>255</span>), <span style=color:#ae81ff>2</span>)
            rects <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>array([[x, y, x <span style=color:#f92672>+</span> w, y <span style=color:#f92672>+</span> h] <span style=color:#66d9ef>for</span> (x, y, w, h) <span style=color:#f92672>in</span> rects])
            pick <span style=color:#f92672>=</span> non_max_suppression(rects, probs<span style=color:#f92672>=</span><span style=color:#66d9ef>None</span>, overlapThresh<span style=color:#f92672>=</span><span style=color:#ae81ff>0.65</span>)
            <span style=color:#66d9ef>for</span> (xA, yA, xB, yB) <span style=color:#f92672>in</span> pick:
                cv2<span style=color:#f92672>.</span>rectangle(image, (xA, yA), (xB, yB), (<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>255</span>, <span style=color:#ae81ff>0</span>), <span style=color:#ae81ff>2</span>)
        <span style=color:#75715e># show the output images</span>
        cv2<span style=color:#f92672>.</span>imshow(<span style=color:#e6db74>&#34;Result&#34;</span>, cv2<span style=color:#f92672>.</span>resize(image, screen_size))
        key<span style=color:#f92672>=</span>cv2<span style=color:#f92672>.</span>waitKey(<span style=color:#ae81ff>1</span>) <span style=color:#75715e># ms delay</span>
        <span style=color:#66d9ef>if</span> key<span style=color:#f92672>==</span><span style=color:#ae81ff>27</span>:
                cap<span style=color:#f92672>.</span>release()
                cv2<span style=color:#f92672>.</span>destroyAllWindows()
                <span style=color:#66d9ef>break</span>
cap<span style=color:#f92672>.</span>release()
cv2<span style=color:#f92672>.</span>destroyAllWindows()
</code></pre></div><p><img loading=lazy src=qc1.jpg alt="photo of the quadcopter"></p><p><img loading=lazy src=qc2.jpg alt="photo of the receiver board"></p><p><img loading=lazy src=qc3.jpg alt="photo of the monitor and controller"></p><p><img loading=lazy src=qc4.jpg alt="photo of the image processing on a TV screen"></p></div><footer class=post-footer></footer></article></main></body></html>